{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from colorama import Fore, Style\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from utils import ModelWrapper, XGBWrapper\n",
    "from utils.preprocess import load_all\n",
    "from utils.utils import (\n",
    "    highlight_print, timer, submit, calculate_feature_importance, load_feats,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_feats(df):\n",
    "    df['BAO_CREDIT__ANNUNITY'] = df['ACTIVE_AMT_CREDIT_SUM_SUM'] / df['AMT_ANNUITY']\n",
    "    df['BAO_CREDIT__INC'] = df['ACTIVE_AMT_CREDIT_SUM_SUM'] / df['AMT_INCOME_TOTAL']\n",
    "    df['BAO_CREDIT__CREDIT'] = df['ACTIVE_AMT_CREDIT_SUM_SUM'] / df['AMT_CREDIT']\n",
    "    df['BAO_CREDIT__GOODS'] = df['ACTIVE_AMT_CREDIT_SUM_SUM'] / df['AMT_GOODS_PRICE']\n",
    "    \n",
    "    df['PAO_CREDIT__ANNUNITY'] = df['PREV_AMT_CREDIT_MEAN'] / df['AMT_ANNUITY']\n",
    "    df['PAO_CREDIT__INC'] = df['PREV_AMT_CREDIT_MEAN'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAO_CREDIT__CREDIT'] = df['PREV_AMT_CREDIT_MEAN'] / df['AMT_CREDIT']\n",
    "    df['PAO_CREDIT__GOODS'] = df['PREV_AMT_CREDIT_MEAN'] / df['AMT_GOODS_PRICE']\n",
    "    \n",
    "    df['PAO_ANNUNITY'] = df['PREV_AMT_ANNUITY_MEAN'] / df['AMT_ANNUITY']\n",
    "    df['PAO_ANNUNITY__INC'] = df['PREV_AMT_ANNUITY_MEAN'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAO_ANNUNITY__CREDIT'] = df['PREV_AMT_ANNUITY_MEAN'] / df['AMT_CREDIT']\n",
    "    \n",
    "    df[\"IBO_PAYMENT__ACREDIT\"] = df[\"INSTAL_AMT_PAYMENT_SUM\"] / df['ACTIVE_AMT_CREDIT_SUM_SUM']\n",
    "    df[\"IBO_PAYMENT__CCREDIT\"] = df[\"INSTAL_AMT_PAYMENT_SUM\"] / df['CLOSED_AMT_CREDIT_SUM_SUM']\n",
    "    df[\"IAO_PAYMENT__ANNUITY\"] = df[\"INSTAL_AMT_PAYMENT_SUM\"] / df['AMT_ANNUITY']\n",
    "    df[\"IAO_PAYMENT__INC\"] = df[\"INSTAL_AMT_PAYMENT_SUM\"] / df['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (356251, 998)\n",
      "\u001b[92m[Done] Load features at 2018-08-28 11:45:53.451369\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with timer('Load features'):\n",
    "    df = load_all('../data/preprocess')\n",
    "    print(\"df shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_exp shape: (356251, 1013)\n"
     ]
    }
   ],
   "source": [
    "df_exp = df.copy()\n",
    "df_exp = exp_feats(df)\n",
    "print(\"df_exp shape:\", df_exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_exp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load feats from: 91_m_lgbm5_best\n",
      "feats num: 709, drop_feats: 364\n"
     ]
    }
   ],
   "source": [
    "base = '91_m_lgbm5_best'\n",
    "model_folder = os.path.join('..', 'expmodel', base)\n",
    "feats = load_feats(model_folder, 'feats.json')\n",
    "\n",
    "drop_feats = []\n",
    "if feats is not None:\n",
    "    print('Load feats from: {}'.format(base))\n",
    "    drop_feats = list(set(df_full.columns) - set(feats))\n",
    "else:\n",
    "    skip_feats = ['TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'index'] + drop_feats\n",
    "    feats = [f for f in df_full.columns if f not in skip_feats]\n",
    "print('feats num: {}, drop_feats: {}'.format(len(feats), len(drop_feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abawchen/.virtualenvs/ml-playground/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/abawchen/.virtualenvs/ml-playground/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_full shape: (356251, 1073), selected_generated_feats: 60\n",
      "df_gen shape: (356251, 1073), feats num: 709\n"
     ]
    }
   ],
   "source": [
    "df_full, selected_generated_feats = process_generated_feats(df_full, feats)\n",
    "print('df_full shape: {}, selected_generated_feats: {}'.format(\n",
    "    df_full.shape, len(selected_generated_feats)))\n",
    "df_gen = df_full.copy()\n",
    "print('df_gen shape: {}, feats num: {}'.format(df_gen.shape, len(feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/38134049\n",
    "df_rf = df_gen.copy()\n",
    "df_rf[feats] = df_rf[feats].fillna(df_rf.median()).replace([np.inf, -np.inf], df_rf.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_rf[df_rf['TARGET'].notnull()]\n",
    "test_df = df_rf[df_rf['TARGET'].isnull()]\n",
    "print(\"train_df shape:\", train_df.shape)\n",
    "print(\"test_df shape:\", test_df.shape)\n",
    "\n",
    "X_train = train_df[feats]\n",
    "X_test = test_df[feats]\n",
    "y_train = train_df['TARGET']\n",
    "print(\"X_train df shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(n_fold, clf, feats):\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = n_fold+1\n",
    "    return fold_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ModelWrapper)\n",
    "\n",
    "r = 1\n",
    "nums_fold = 5\n",
    "random_state = 1001\n",
    "prefix = '106_{}_rf{}_{}'.format('m', nums_fold, str(r).zfill(2))\n",
    "# prefix = 'xgb_10x_3'\n",
    "model_folder = os.path.join('..', 'expmodel', '{}'.format(prefix))\n",
    "params = {}\n",
    "params = {\n",
    "    'n_estimators': 56,\n",
    "    'max_depth': 8,\n",
    "    'class_weight': 'balanced',\n",
    "    'min_samples_leaf': 4\n",
    "}\n",
    "\"\"\"\n",
    "#             n_estimators=55,\n",
    "#             max_depth=9,\n",
    "#             class_weight='balanced',\n",
    "#             random_state=42,\n",
    "#             min_samples_leaf=5,\n",
    "\n",
    "\"\"\"\n",
    "params['n_jobs'] = -1\n",
    "params['verbose'] = True\n",
    "\n",
    "fit_params = {}\n",
    "model = ModelWrapper.ModelWrapper(\n",
    "    CLF=RandomForestClassifier,\n",
    "    name=\"RandomForest\",\n",
    "    model_folder=model_folder,\n",
    "    feats=feats,\n",
    "    drop_feats=drop_feats,\n",
    "    params=params,\n",
    "    fit_params=fit_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats num: 709\n",
      "model folder: ../expmodel/106_m_rf5_01\n",
      "../expmodel/106_m_rf5_01/RandomForest_0.pickle not exists, going to train.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ccbdc6e539b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeature_importance_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnums_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_auc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolds_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mhighlight_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLIGHTBLUE_EX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'- %.6f (%s)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfold_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfold_importance_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/project/github/abawchen/ml-playground/kaggle/home-credit-default-risk/ipynb/utils/ModelWrapper.py\u001b[0m in \u001b[0;36mfolds_train\u001b[0;34m(self, folds, X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mfold_x_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_y_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             self._train(\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mn_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_x_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_y_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             )\n\u001b[1;32m     83\u001b[0m             oof_preds_filename = os.path.join(\n",
      "\u001b[0;32m~/workspace/project/github/abawchen/ml-playground/kaggle/home-credit-default-risk/ipynb/utils/ModelWrapper.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, n_fold, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mfit_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'early_stopping_rounds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/project/github/abawchen/ml-playground/kaggle/home-credit-default-risk/ipynb/utils/ModelWrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml-playground/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml-playground/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml-playground/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "n_fold = 0\n",
    "random_state = 1001\n",
    "feature_importance_df = pd.DataFrame()\n",
    "folds = KFold(n_splits=nums_fold, shuffle=True, random_state=random_state)\n",
    "for clf, fold_auc in model.folds_train(folds, X_train, y_train, X_test):\n",
    "    highlight_print(Fore.LIGHTBLUE_EX, '- %.6f (%s)' % (fold_auc, datetime.datetime.now()))\n",
    "    fold_importance_df = feature_importance(n_fold, clf, feats)\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    n_fold += 1\n",
    "    del clf , fold_importance_df\n",
    "    gc.collect()\n",
    "        \n",
    "score = roc_auc_score(y_train, model.oof_preds_df)\n",
    "highlight_print(Fore.RED, '## RF: %.6f' % score)\n",
    "model.scores.append(score)\n",
    "model.serialize_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission/lgbm_10xx_5-2018_08_02_13_20_17.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abaw/.virtualenvs/ml-playground/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "n_iter = 5\n",
    "n_splits = 5\n",
    "prefix = '106_{}_xgb{}_{}_{}'.format('b', n_splits, n_iter, str(r).zfill(2))\n",
    "model_folder = os.path.join('..', 'expmodel', prefix)\n",
    "\n",
    "b_round = 0\n",
    "b_feature_importance_df = pd.DataFrame()\n",
    "\n",
    "def xgb_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "    global b_feature_importance_df\n",
    "    global b_round\n",
    "\n",
    "    params['n_estimators'] = 10000\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['verbose'] = True\n",
    "\n",
    "    submodel_folder = os.path.join(model_folder, str(b_round))\n",
    "    try:\n",
    "        os.makedirs(submodel_folder)\n",
    "    except:\n",
    "        pass\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=1001)\n",
    "    b_model = ModelWrapper.ModelWrapper(\n",
    "        CLF=XGBClassifier,\n",
    "        name=\"XGBBoost\",\n",
    "        model_folder=submodel_folder,\n",
    "        feats=feats,\n",
    "        drop_feats=drop_feats,\n",
    "        params=params,\n",
    "        fit_params=fit_params\n",
    "    )\n",
    "    n_fold = 0\n",
    "    for clf, fold_auc in b_model.folds_train(folds, X_train, y_train, X_test):\n",
    "        fold_importance_df = feature_importance(n_fold, clf, feats)\n",
    "        b_feature_importance_df = pd.concat([b_feature_importance_df, fold_importance_df], axis=0)\n",
    "        n_fold += 1\n",
    "        del clf, fold_importance_df\n",
    "        gc.collect()\n",
    "\n",
    "    score = roc_auc_score(y_train, b_model.oof_preds_df)\n",
    "    b_model.scores.append(score)\n",
    "    b_model.serialize_scores()\n",
    "    b_round += 1\n",
    "    return score\n",
    "\n",
    "with timer(\"BayesianOptimization:\"):\n",
    "    b_params = {'colsample_bytree': (0.8, 1),\n",
    "              'learning_rate': (.01, .02), \n",
    "              'num_leaves': (33, 35), \n",
    "              'subsample': (0.8, 1), \n",
    "              'max_depth': (7, 9), \n",
    "              'reg_alpha': (.03, .05), \n",
    "              'reg_lambda': (.06, .08), \n",
    "              'min_split_gain': (.01, .03),\n",
    "              'min_child_weight': (38, 40)}\n",
    "    bo = BayesianOptimization(xgb_evaluate, b_params)\n",
    "    bo.maximize(init_points=5, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_generated_feats(df, feats):\n",
    "    sg = {\n",
    "        '+': [], '-': [], '*': [], '/': [], '^':[]\n",
    "    }\n",
    "    x_dup_combos = [\n",
    "        ('AAAO_SOURCES_MEAN__EMPLOYED_BIRTH', 'AAO_EMPLOYED__BIRTH'),\n",
    "    ]\n",
    "    o_dup_combos = [\n",
    "        ('AAAX_CREDIT_ANNUITY__EMPLOYED', 'DAYS_EMPLOYED'),\n",
    "        ('AAO_EMPLOYED__BIRTH', 'DAYS_EMPLOYED'),\n",
    "        ('AAO_ANNUITY__INC', 'AAO_CREDIT__INC'),\n",
    "    ]\n",
    "    for feat in feats:\n",
    "        if feat.startswith('*:') or \\\n",
    "            feat.startswith('/:') or \\\n",
    "            feat.startswith('+:') or \\\n",
    "            feat.startswith('-:') or \\\n",
    "            feat.startswith('^:'):\n",
    "            operator = feat[0]\n",
    "            f1, f2 = feat[2:].split('-')\n",
    "            if operator == '*' and (f1, f2) in x_dup_combos:\n",
    "                continue\n",
    "            if operator == '/' and (f1, f2) in o_dup_combos:\n",
    "                continue\n",
    "            sg[operator].append((f1, f2))\n",
    "    operators = {\n",
    "         '*': np.multiply,\n",
    "         '/': np.divide,\n",
    "         '+': np.add,\n",
    "         '-': np.subtract,\n",
    "         '^': np.power\n",
    "    }\n",
    "    generated_feats = []\n",
    "    for k, v in sg.items():\n",
    "        for (f1, f2) in v:\n",
    "            name = '{}:{}-{}'.format(k, f1, f2)\n",
    "            generated_feats.append(name)\n",
    "            df[name] = operators[k](df[f1], df[f2])\n",
    "    return df, generated_feats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
